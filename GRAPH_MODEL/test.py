import os

from sklearn.metrics import confusion_matrix
import torch
import numpy as np
import dgl
import cv2
import pandas as pd
from dataset import SROIEDataset
from gated_gcn import GatedGCNNet

def accuracy(scores, targets):
    S = targets.cpu().numpy()
    C = np.argmax( torch.nn.Softmax(dim=1)(scores).cpu().detach().numpy() , axis=1 )
    CM = confusion_matrix(S,C).astype(np.float32)
    # import pdb; pdb.set_trace()
    nb_classes = CM.shape[0]
    targets = targets.cpu().detach().numpy()
    nb_non_empty_classes = 0
    recall = np.zeros(nb_classes)
    precision = np.zeros(nb_classes)
    F1_score = np.zeros(nb_classes)

    for r in range(nb_classes):
        cluster = np.where(targets==r)[0]
        if cluster.shape[0] != 0:
            recall[r] = CM[r,r]/ float(cluster.shape[0])
            if np.sum(CM[:, r]) > 0:
                precision[r] = CM[r,r] / np.sum(CM[:, r])
            else:
                precision[r] = 0.0

            if (precision[r] + recall[r]) > 0.:
                F1_score[r] = 2 * recall[r] * precision[r] / (precision[r] + recall[r])
            else:
                F1_score[r] == 0.

            if CM[r,r]>0:
                nb_non_empty_classes += 1
        else:
            recall[r] = 0.0
            precision[r] = 0.0
            F1_score[r] = 0.0
    return recall, precision, F1_score

def _text_encode(text):
        text_encode = []
        for t in text.upper():   #             
            if t not in alphabet:
                text_encode.append(alphabet.index(" "))
            else:
                text_encode.append(alphabet.index(t))
        return np.array(text_encode)

def _load_annotation(annotation_file):
    # import pdb; pdb.set_trace()    
    # print(annotation_file)
    texts = []
    text_lengths = []
    boxes = []
    labels = []
    original = []
    with open(annotation_file) as f:
        lines = f.readlines()
        for line in lines:
            splits = line.strip().split('\t')
            if len(splits) < 10:
                continue
            text_encode = _text_encode(splits[8])
            original.append(splits[8])
            text_lengths.append(text_encode.shape[0])
            texts.append(text_encode)
            box_info = [int(x) for x in splits[:8]]
        
            box_info.append(np.max(box_info[0::2]) - np.min(box_info[0::2]))
            box_info.append(np.max(box_info[1::2]) - np.min(box_info[1::2]))
            boxes.append([int(x) for x in box_info])
            labels.append(node_labels.index(splits[9]))
            # labels.append(0)
        # print("---------",annotation_file)
        # print("---------",np.array(boxes).shape)
    return np.array(texts), np.array(text_lengths), np.array(boxes), np.array(labels),original


def _prepapre_pipeline(boxes, edge_data, text, text_length):
    box_min = boxes.min(0)
    box_max = boxes.max(0)

    boxes = (boxes - box_min) / (box_max - box_min)
    boxes = (boxes - 0.5) / 0.5

    edge_min = edge_data.min(0)
    edge_max = edge_data.max(0)

    edge_data = (edge_data - edge_min) / (edge_max - edge_min)
    edge_data = (edge_data - 0.5) / 0.5

    return boxes, edge_data, text, text_length

def load_data(annotation_file):
    texts, text_lengths, boxes, labels,original = _load_annotation(annotation_file)

    origin_boxes = boxes
    node_nums = text_lengths.shape[0]
    src = []
    dst = []
    edge_data = []
    for i in range(node_nums):
        for j in range(node_nums):
            if i == j:
                continue
                
            edata = []
            #y distance
            y_distance = np.mean(boxes[i][:8][1::2]) - np.mean(boxes[j][:8][1::2])
            x_distance = np.mean(boxes[i][:8][0::2]) - np.mean(boxes[j][:8][0::2])
            w = boxes[i, 8]
            h = boxes[i, 9]

            if np.abs(y_distance) >  3 * h:
                continue
            
            edata.append(y_distance)
            edata.append(x_distance)

            edge_data.append(edata)
            src.append(i)
            dst.append(j)

    edge_data = np.array(edge_data)
    g = dgl.DGLGraph()
    g = g.to('cuda:0')
    g.add_nodes(node_nums)
    g.add_edges(src, dst)
    

    boxes, edge_data, text, text_length = _prepapre_pipeline(boxes, edge_data, texts, text_lengths)

    boxes = torch.from_numpy(boxes).float()
    edge_data = torch.from_numpy(edge_data).float()

    tab_sizes_n = g.number_of_nodes()
    tab_snorm_n = torch.FloatTensor(tab_sizes_n, 1).fill_(1./float(tab_sizes_n))
    snorm_n = tab_snorm_n.sqrt()  

    tab_sizes_e = g.number_of_edges()
    tab_snorm_e = torch.FloatTensor(tab_sizes_e, 1).fill_(1./float(tab_sizes_e))
    snorm_e = tab_snorm_e.sqrt()

    max_length = text_lengths.max()
    new_text = [np.expand_dims(np.pad(t, (0, max_length - t.shape[0]), 'constant'), axis=0) for t in text]
    texts = np.concatenate(new_text)

    labels = torch.from_numpy(np.array(labels))
    texts = torch.from_numpy(np.array(texts))
    text_length = torch.from_numpy(np.array(text_length))

    graph_node_size = [g.number_of_nodes()]
    graph_edge_size = [g.number_of_edges()]

    return g, labels, boxes, edge_data, snorm_n, snorm_e, texts, text_length, origin_boxes, annotation_file, graph_node_size, graph_edge_size,original


def load_gate_gcn_net(device, checkpoint_path):
    net_params = {}
    net_params['in_dim_text'] = len(alphabet)
    net_params['in_dim_node'] = 10
    net_params['in_dim_edge'] = 2
    net_params['hidden_dim'] = 512
    net_params['out_dim'] = 512
    net_params['n_classes'] = 5
    net_params['in_feat_dropout'] = 0.1
    net_params['dropout'] = 0.0
    net_params['L'] = 8
    net_params['readout'] = True
    net_params['graph_norm'] = True
    net_params['batch_norm'] = True
    net_params['residual'] = True
    net_params['device'] = 'cuda'
    net_params['OHEM'] = 3

    model = GatedGCNNet(net_params)

    checkpoint = torch.load(checkpoint_path)
    model.load_state_dict(checkpoint)

    model = model.to(device)
    model.eval()
    return model


node_labels = ['other', 'company', 'address', 'date', 'total']
alphabet = ' "$(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_ÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚÝĂĐĨŨƠƯẠẢẤẦẨẪẬẮẰẲẴẶẸẺẼẾỀỂỄỆỈỊỌỎỐỒỔỖỘỚỜỞỠỢỤỦỨỪỬỮỰỲỴỶỸ'

def main():
    data_path = "/media/thorpham/PROJECT/OCR-challenge/preprocessing/OCR_rotated/"
    image_path = "/media/thorpham/PROJECT/OCR-challenge/image_rotated/"
    checkpoint_path = './checkpoints/test_newest.pkl'
    device = 'cuda'
    model = load_gate_gcn_net(device, checkpoint_path)

    acc_right  = [0, 0, 0, 0]
    annotation_list = os.listdir(data_path)
    data_frame = []
    for annotation_file in annotation_list:
        if 'jpg' in annotation_file:
            continue
        print(annotation_file) 
        with open(f"rs1/{annotation_file}","w") as f :
            annotation_path = os.path.join(data_path, annotation_file)
            
            batch_graphs, batch_labels, batch_x, batch_e, batch_snorm_n, batch_snorm_e, text, text_length, boxes, ann_file, graph_node_size, graph_edge_size,original = load_data(annotation_path)

            batch_x = batch_x.to(device)  # num x feat
            batch_e = batch_e.to(device)

            text = text.to(device)
            text_length =  text_length.to(device)        
            batch_snorm_e = batch_snorm_e.to(device)
            batch_snorm_n = batch_snorm_n.to(device) 
                # num x 1

            batch_scores = model.forward(batch_graphs, batch_x, batch_e, text, text_length, batch_snorm_n, batch_snorm_e,graph_node_size, graph_edge_size)

            image_file = os.path.join(image_path, os.path.basename(ann_file).replace("txt", 'jpg'))
            
            if not os.path.exists(image_file):
                continue

            image = cv2.imread(image_file)

            batch_scores = batch_scores.cpu().softmax(1)
            values, pred = batch_scores.max(1)

            length = pred.shape[0]
            results = {"company":[],"address":[],"date":[],"total":[]}
            save = []
            for i in range(length):
                if pred[i] == batch_labels[i]:
                    if pred[i] == 0:
                        continue

                    msg = "{}".format(node_labels[pred[i]])
                    color = (0, 255, 0)
                else:
                    # msg = "{}-{}".format(node_labels[pred[i]], node_labels[batch_labels[i]])
                    msg = "{}".format(node_labels[pred[i]])
                    color = (0, 0, 255)

                info = boxes[i]
                box = np.array([[int(info[0]), int(info[1])], [int(info[2]), int(info[3])], [int(info[4]), int(info[5])], [int(info[6]), int(info[7])]])
                s = original[i]
                save = info.tolist()
                save.extend([s,msg])
                f.write("\t".join([str(i) for i in save])+"\n")
            # print("image ",file_name)
            # ocr = text[i].detach().cpu().numpy()
            # s = ""
            # for i in ocr :
            #     if i != 0 :
            #         s += alphabet[i]
            # print(ocr)
            # if len(s)>2:
        #     s = original[i]
        #     results[msg].append(s)
                # cv2.polylines(image, [box], 1, color)
                # cv2.putText(image, msg , (int(info[0]), int(info[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)
        # # print(results)
        # name_image = os.path.basename(image_file)
        # company =  " ".join([str(i.strip()) for i in results["company"]])
        # address =  " ".join([str(i.strip()) for i in results["address"]])
        # date =  " ".join([str(i.strip()) for i in results["date"]])
        # total =  " ".join([str(i.strip()) for i in results["total"]])
        # out = company + "|||" + address + "|||" + date+ "|||" + total
        # print(out)
        # data_frame.append([name_image,0.5,out.strip()])
    #     file_name = os.path.basename(image_file)
        
    #     cv2.imshow("im",cv2.resize(image,(400,600)))
    #     cv2.waitKey(0)
    # cv2.destroyAllWindows()
        # cv2.imwrite('./visual_test/{}'.format(file_name), image)
    # data_frame.append(["mcocr_val_145114unyae.jpg",0.5,"|||||||||"])
    # columns = ["img_id","anno_image_quality","anno_texts"]
    # df = pd.DataFrame(data_frame,columns=columns)
    # # print(df.head())
    # # print(len(df["img_id"].unique()))
    # df.to_csv("results.csv",index=None,columns=columns)
    #     # file_name = os.path.basename(image_file)
        # cv2.imwrite('./visual_test/{}'.format(file_name), image)

if __name__ == '__main__':
    main()
